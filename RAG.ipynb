{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4f6f298d4e2746fd9141fb78ab682210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43b07c75f5fd44e1884b3371fe872287",
              "IPY_MODEL_26c4cf3b9b964b3abbeeb87d46b068b0",
              "IPY_MODEL_62610a3c9f704ab5a0e085f4d084b83f"
            ],
            "layout": "IPY_MODEL_56a32ab537544bb1ab8c290eec79206d"
          }
        },
        "43b07c75f5fd44e1884b3371fe872287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca96c22d45bc4d07b6cea97601ecbeac",
            "placeholder": "​",
            "style": "IPY_MODEL_4060366115a0453eb56103f28ce6376f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "26c4cf3b9b964b3abbeeb87d46b068b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0608246a3b6e454c85b3daf70c73b666",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1aca87ba621641fea2ad967e29b9eb81",
            "value": 2
          }
        },
        "62610a3c9f704ab5a0e085f4d084b83f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d20e3f8982d94d75b8c07b9ee5565019",
            "placeholder": "​",
            "style": "IPY_MODEL_6f44d25fb4734e1e929a4db1fa246386",
            "value": " 2/2 [00:00&lt;00:00,  2.05it/s]"
          }
        },
        "56a32ab537544bb1ab8c290eec79206d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca96c22d45bc4d07b6cea97601ecbeac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4060366115a0453eb56103f28ce6376f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0608246a3b6e454c85b3daf70c73b666": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aca87ba621641fea2ad967e29b9eb81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d20e3f8982d94d75b8c07b9ee5565019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f44d25fb4734e1e929a4db1fa246386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaqSIsPaD29o",
        "outputId": "6c6da932-6cb2-4a9a-f130-da378f6cb1cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Collecting Rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.129)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.5.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Rouge) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n",
            "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: Rouge\n",
            "Successfully installed Rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install langchain-community transformers datasets faiss-cpu sentence-transformers Rouge\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from datasets import load_dataset\n",
        "from rouge import Rouge\n",
        "\n",
        "dataset = load_dataset(\"squad\", split=\"train[:1000]\")  # Using first 1000 examples for demonstration\n",
        "\n",
        "\n",
        "documents = [\n",
        "    {\"content\": context, \"metadata\": {\"title\": title}}\n",
        "    for context, title in zip(dataset[\"context\"], dataset[\"title\"])\n",
        "]\n",
        "\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "texts = text_splitter.create_documents([doc[\"content\"] for doc in documents])\n",
        "\n",
        "\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "\n",
        "vectorstore = FAISS.from_documents(texts, embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms8dp9DzD6yu",
        "outputId": "25319c1f-2d50-4d32-cea3-41b0aa1e2db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "generator = pipeline(\"text2text-generation\", model=\"HuggingFaceTB/cosmo-1b\", device= 0 , max_new_tokens = 50 )\n",
        "llm = HuggingFacePipeline(pipeline=generator)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "4f6f298d4e2746fd9141fb78ab682210",
            "43b07c75f5fd44e1884b3371fe872287",
            "26c4cf3b9b964b3abbeeb87d46b068b0",
            "62610a3c9f704ab5a0e085f4d084b83f",
            "56a32ab537544bb1ab8c290eec79206d",
            "ca96c22d45bc4d07b6cea97601ecbeac",
            "4060366115a0453eb56103f28ce6376f",
            "0608246a3b6e454c85b3daf70c73b666",
            "1aca87ba621641fea2ad967e29b9eb81",
            "d20e3f8982d94d75b8c07b9ee5565019",
            "6f44d25fb4734e1e929a4db1fa246386"
          ]
        },
        "id": "pByPooDsHGk3",
        "outputId": "6c09fb8c-34bf-4639-c083-56a95b2f7477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f6f298d4e2746fd9141fb78ab682210"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'LlamaForCausalLM' is not supported for text2text-generation. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.base import Chain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from typing import Dict, List, Any\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "\n",
        "prompt_template = \"\"\"You question-answering task assistant.\n",
        "Answer the question only based on your context and knowledge.\n",
        "If you do not know the answer with given context, say that you do not know.\n",
        "Use the following context:\n",
        "{context}\n",
        "Answer the following question: {question}\n",
        "Answer: \"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})  # Retrieve top 3 documents\n",
        "\n",
        "\n",
        "def custom_qa_chain(llm, prompt, retriever):\n",
        "    qa = load_qa_chain(llm, chain_type=\"stuff\", prompt=prompt)\n",
        "\n",
        "    def _run(query: str):\n",
        "        docs = retriever.get_relevant_documents(query)\n",
        "        result = qa({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)\n",
        "        return {\"result\": result[\"output_text\"], \"source_documents\": docs}\n",
        "\n",
        "    return _run\n",
        "\n",
        "\n",
        "qa_chain = custom_qa_chain(llm, PROMPT, retriever)\n"
      ],
      "metadata": {
        "id": "ibCaLliiHQlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset = load_dataset(\"squad\", split=\"validation[:90]\")  # Using first 100 examples for brevity\n",
        "\n",
        "\n",
        "rouge = Rouge()\n",
        "\n",
        "def evaluate_rag(qa_chain, dataset):\n",
        "    rouge_scores = []\n",
        "    retrieval_precision_scores = []\n",
        "\n",
        "    for example in tqdm(dataset):\n",
        "        question = example['question']\n",
        "        ground_truth = example['answers']['text'][0]\n",
        "\n",
        "\n",
        "        rag_response = qa_chain(question)\n",
        "        generated_answer = rag_response['result']\n",
        "        generated_answer = re.split('Answer:',generated_answer)[-1]\n",
        "        generated_answer= re.split(r'\\n\\n', generated_answer)[0]  # Truncate at the first \\n\\n\n",
        "        retrieved_docs = rag_response['source_documents']\n",
        "\n",
        "\n",
        "        rouge_score = rouge.get_scores(generated_answer, ground_truth)[0]\n",
        "        rouge_scores.append(rouge_score['rouge-l']['f'])\n",
        "\n",
        "\n",
        "        relevant_docs = [doc for doc in retrieved_docs if ground_truth.lower() in doc.page_content.lower()]\n",
        "        retrieval_precision = len(relevant_docs) / len(retrieved_docs) if retrieved_docs else 0\n",
        "        retrieval_precision_scores.append(retrieval_precision)\n",
        "\n",
        "\n",
        "    avg_rouge = np.mean(rouge_scores)\n",
        "    avg_retrieval_precision = np.mean(retrieval_precision_scores)\n",
        "\n",
        "    return {\n",
        "        \"avg_rouge_l_f1\": avg_rouge,\n",
        "        \"avg_retrieval_precision\": avg_retrieval_precision\n",
        "    }"
      ],
      "metadata": {
        "id": "AvbIw_cOo8eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "evaluation_results = evaluate_rag(qa_chain, dataset)\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Average ROUGE-L F1: {evaluation_results['avg_rouge_l_f1']:.4f}\")\n",
        "print(f\"Average Retrieval Precision: {evaluation_results['avg_retrieval_precision']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi1Myn8ApC7z",
        "outputId": "8d9fa136-a7a9-45ab-ae0a-f21359d0d3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/90 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  1%|          | 1/90 [00:01<02:39,  1.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  2%|▏         | 2/90 [00:03<02:34,  1.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  3%|▎         | 3/90 [00:05<02:32,  1.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  4%|▍         | 4/90 [00:07<02:33,  1.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  6%|▌         | 5/90 [00:08<02:33,  1.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  7%|▋         | 6/90 [00:10<02:29,  1.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  8%|▊         | 7/90 [00:12<02:35,  1.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  9%|▉         | 8/90 [00:14<02:40,  1.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 10%|█         | 9/90 [00:16<02:32,  1.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 11%|█         | 10/90 [00:18<02:38,  1.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 12%|█▏        | 11/90 [00:21<02:41,  2.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 13%|█▎        | 12/90 [00:22<02:32,  1.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 14%|█▍        | 13/90 [00:24<02:25,  1.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 16%|█▌        | 14/90 [00:26<02:19,  1.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 17%|█▋        | 15/90 [00:27<02:16,  1.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 18%|█▊        | 16/90 [00:29<02:12,  1.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 19%|█▉        | 17/90 [00:31<02:18,  1.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 20%|██        | 18/90 [00:33<02:15,  1.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 21%|██        | 19/90 [00:35<02:11,  1.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 22%|██▏       | 20/90 [00:37<02:07,  1.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 23%|██▎       | 21/90 [00:38<02:04,  1.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 24%|██▍       | 22/90 [00:40<02:01,  1.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 26%|██▌       | 23/90 [00:42<01:58,  1.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 27%|██▋       | 24/90 [00:44<01:56,  1.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 28%|██▊       | 25/90 [00:46<01:56,  1.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 29%|██▉       | 26/90 [00:47<01:55,  1.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 30%|███       | 27/90 [00:49<01:52,  1.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 31%|███       | 28/90 [00:51<01:50,  1.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 32%|███▏      | 29/90 [00:53<01:47,  1.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 33%|███▎      | 30/90 [00:54<01:45,  1.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 34%|███▍      | 31/90 [00:56<01:47,  1.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 36%|███▌      | 32/90 [00:59<01:52,  1.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 37%|███▋      | 33/90 [01:01<01:54,  2.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 38%|███▊      | 34/90 [01:03<01:52,  2.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 39%|███▉      | 35/90 [01:04<01:45,  1.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 40%|████      | 36/90 [01:06<01:45,  1.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 41%|████      | 37/90 [01:08<01:44,  1.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 42%|████▏     | 38/90 [01:10<01:39,  1.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 43%|████▎     | 39/90 [01:12<01:41,  1.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 44%|████▍     | 40/90 [01:15<01:41,  2.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 46%|████▌     | 41/90 [01:17<01:43,  2.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 47%|████▋     | 42/90 [01:19<01:42,  2.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 48%|████▊     | 43/90 [01:21<01:38,  2.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 49%|████▉     | 44/90 [01:23<01:37,  2.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 50%|█████     | 45/90 [01:25<01:32,  2.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 51%|█████     | 46/90 [01:27<01:31,  2.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 52%|█████▏    | 47/90 [01:29<01:28,  2.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 53%|█████▎    | 48/90 [01:31<01:27,  2.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 54%|█████▍    | 49/90 [01:33<01:24,  2.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 56%|█████▌    | 50/90 [01:36<01:23,  2.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 57%|█████▋    | 51/90 [01:39<01:36,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 58%|█████▊    | 52/90 [01:41<01:30,  2.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 59%|█████▉    | 53/90 [01:43<01:25,  2.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 60%|██████    | 54/90 [01:45<01:17,  2.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 61%|██████    | 55/90 [01:48<01:23,  2.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 62%|██████▏   | 56/90 [01:50<01:15,  2.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 63%|██████▎   | 57/90 [01:52<01:10,  2.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 64%|██████▍   | 58/90 [01:54<01:07,  2.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 66%|██████▌   | 59/90 [01:56<01:04,  2.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 67%|██████▋   | 60/90 [01:58<01:00,  2.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 68%|██████▊   | 61/90 [02:00<00:58,  2.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 69%|██████▉   | 62/90 [02:02<00:56,  2.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 70%|███████   | 63/90 [02:04<00:53,  1.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 71%|███████   | 64/90 [02:06<00:53,  2.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 72%|███████▏  | 65/90 [02:08<00:49,  1.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 73%|███████▎  | 66/90 [02:10<00:48,  2.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 74%|███████▍  | 67/90 [02:12<00:46,  2.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 76%|███████▌  | 68/90 [02:14<00:43,  1.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 77%|███████▋  | 69/90 [02:16<00:41,  1.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 78%|███████▊  | 70/90 [02:17<00:38,  1.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 79%|███████▉  | 71/90 [02:19<00:35,  1.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 80%|████████  | 72/90 [02:21<00:33,  1.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 81%|████████  | 73/90 [02:23<00:32,  1.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 82%|████████▏ | 74/90 [02:25<00:31,  1.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 83%|████████▎ | 75/90 [02:27<00:29,  1.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 84%|████████▍ | 76/90 [02:29<00:28,  2.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 86%|████████▌ | 77/90 [02:31<00:27,  2.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 87%|████████▋ | 78/90 [02:34<00:25,  2.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 88%|████████▊ | 79/90 [02:36<00:23,  2.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 89%|████████▉ | 80/90 [02:38<00:20,  2.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 90%|█████████ | 81/90 [02:39<00:17,  1.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 91%|█████████ | 82/90 [02:42<00:16,  2.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 92%|█████████▏| 83/90 [02:44<00:14,  2.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 93%|█████████▎| 84/90 [02:45<00:11,  1.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 94%|█████████▍| 85/90 [02:47<00:09,  1.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 96%|█████████▌| 86/90 [02:49<00:07,  1.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 97%|█████████▋| 87/90 [02:51<00:05,  2.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 98%|█████████▊| 88/90 [02:53<00:03,  1.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 99%|█████████▉| 89/90 [02:55<00:02,  2.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "100%|██████████| 90/90 [02:57<00:00,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results:\n",
            "Average ROUGE-L F1: 0.0302\n",
            "Average Retrieval Precision: 0.0444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "question = \"Where are Tussauds Wax Museums?\"\n",
        "answer = qa_chain(question)\n",
        "answer['result'] = re.split('Answer:',answer['result'])[-1]\n",
        "answer['result']= re.split(r'\\n\\n', answer['result'])[0]  # Truncate at the first \\n\\n\n",
        "print(answer)\n",
        "print(\"\\nSource Documents:\")\n",
        "for i, doc in enumerate(answer[\"source_documents\"], 1):\n",
        "    print(f\"{i}. {doc.page_content[:100]}...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81UKxV4so-aq",
        "outputId": "76e48488-10ea-4e4c-848d-dffa8b313043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'result': ' 1. New York, Washington, D.C., Amsterdam, Bangkok, Hollywood and Sydney.', 'source_documents': [Document(metadata={}, page_content='Tussauds Wax Museums in major cities around the world, including New York, Washington, D.C., Amsterdam, Bangkok, Hollywood and Sydney.'), Document(metadata={}, page_content='Tussauds Wax Museums in major cities around the world, including New York, Washington, D.C., Amsterdam, Bangkok, Hollywood and Sydney.'), Document(metadata={}, page_content='Tussauds Wax Museums in major cities around the world, including New York, Washington, D.C., Amsterdam, Bangkok, Hollywood and Sydney.')]}\n",
            "\n",
            "Source Documents:\n",
            "1. Tussauds Wax Museums in major cities around the world, including New York, Washington, D.C., Amsterd...\n",
            "2. Tussauds Wax Museums in major cities around the world, including New York, Washington, D.C., Amsterd...\n",
            "3. Tussauds Wax Museums in major cities around the world, including New York, Washington, D.C., Amsterd...\n"
          ]
        }
      ]
    }
  ]
}